<!DOCTYPE HTML>
<!--
Stellar by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Portfolio - Jesse Mehami</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="icon" href="images/robot_dude.svg" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" /> -->
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<!-- <span class="logo"><img src="images/robot_dude.svg" /></span> -->
			<h1>Jesse Mehami</h1>
			<p>Robotics Computer Vision Engineer<br />
			</p>

			<ul class="icons">
				<li>
					<a href="https://www.linkedin.com/in/jessemehami" class="icon brands fa-linkedin alt"
						title="LinkedIn">
					</a>
				</li>
				<li>
					<a href="https://github.com/jmehami1" class="icon brands fa-github alt" title="GitHub">
					</a>
				</li>
				<li>
					<a href="https://scholar.google.com/citations?user=j3bTQ84AAAAJ&hl=en&oi=ao" class="icon fa fa-graduation-cap alt" title="Google Scholar">
					</a>
				</li>
			</ul>

		</header>

		<!-- Nav -->
		<nav id="nav">
			<ul>
				<li><a href="#about" class="active">About</a></li>
				<li><a href="#projects">Projects</a></li>
				<li><a href="#publications">Publications</a></li>
				<li><a href="#education">Education</a></li>
				<li><a href="#footer">Contact</a></li>
			</ul>
		</nav>

				<!-- Add this inside your HTML file where the navigation bar is located -->
		<div id="nav-button" onclick="toggleNav()">â˜°</div>

		<!-- Main -->
		<div id="main">

			<!-- Introduction -->
			<section id="about" class="main">
				<div class="spotlight">
					<div class="content">
						<header class="major">
							<h2>Hi I'm Jesse</h2>
						</header>
						<p>I'm a robotics engineer with an interest in computer vision and machine learning.
							My research has focussed on beyond-vision sensing problems that look at capturing and
							understanding the world that is hidden from us, and bringing it into a space we can
							comprehend.
							</br></br>
							The projects I've completed have focussed on the setup of cameras in a known setup, which
							from my experience has made combining different imaging sensors and estimating shape so much
							easier. I'm now interested in decoding the information that is hidden amongst pixels through
							machine learning and deep learning.
						</p>
					</div>
					<div class="content">

						<span class="image"><img src="images/jesse1.jpg" alt="" /></span>
					</div>
				</div>
				<div>
					<h3>Tools, Languages and Software</h3>

					<div class="icon-row">
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-plain-wordmark.svg"
							alt="Docker" title="Docker">
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/cplusplus/cplusplus-original.svg"
							alt="C++" title="C++" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/matlab/matlab-original.svg"
							alt="MATLAB" title="MATLAB" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original-wordmark.svg"
							alt="Python" title="Python" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/opencv/opencv-original-wordmark.svg"
							alt="OpenCV" title="OpenCV" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original-wordmark.svg"
							alt="Pytorch" title="Pytorch" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/ros/ros-original-wordmark.svg"
							alt="ROS" title="ROS" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/ubuntu/ubuntu-original-wordmark.svg"
							alt="Ubuntu" title="Ubuntu" />
						<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/raspberrypi/raspberrypi-original.svg"
							alt="Raspberry Pi" title="Raspberry Pi" />
						<img src="/images/wandb_logo.svg" alt="Weights and Biases" title="Weights and Biases" />
						<img src="/images/nvidia_logo.svg" alt="Nvidia CUDA and Jetson" title="Nvidia" />
					</div>

					</br>

					<h3>Areas of Expertise</h3>

					<div class="expertise">

						<ul>
							<li>Computer Vision</li>
							<li>Hyperspectral Imaging</li>
							<li>Camera Calibration</li>
							<li>Machine Learning</li>
							<li>Deep Learning</li>
							<li>Multi-Camera Systems</li>
							<li>Statistical Modelling</li>
							<li>Non-Linear Optimization</li>
							<li>Computational Imaging</li>
							<li>Multi-Modal Vision</li>
						</ul>
					</div>
				</div>
			</section>

			<!-- First Section -->
			<section id="projects" class="main special">
				<header class="major">
					<h2>Projects</h2>
					<script>
						function displayImagesFromFolderInRow(containerId) {
							// This function will load all images that are contained in a local file and add them as image attributes to the publication container.
							var container = document.getElementById(containerId);
							var folderPath = "https://api.github.com/repos/jmehami1/jmehami1.github.io/contents/images/projects/" + container.id;

							function isImageFile(fileName) {
								const imageExtensions = ['jpg', 'jpeg', 'png', 'gif'];
								const fileExtension = fileName.toLowerCase().split('.').pop();

								return imageExtensions.includes(fileExtension);
							}

							(async () => {
								const response = await fetch(folderPath);
								const data = await response.json();
								data.forEach(function (fileElement) {

									var filePath = fileElement.path;
									var fileDownloadUrl = fileElement.download_url;

									if (isImageFile(filePath)) {
										var img = new Image();
										img.src = fileDownloadUrl;
										img.alt = filePath;
										container.appendChild(img);
									}
								});
							})()
						}
					</script>
				</header>

				<div class="project">
					<h2>Hyperspectral Deep Learning of Subcutaneous Fat Depth</h2>
					<p>
						<u><strong>Summary</strong></u> I modelled the depth of subcutaneous fat (in millimeters) on
						lamb cuts using <a href="https://en.wikipedia.org/wiki/Hyperspectral_imaging"
							target="_blank">hyperspectral imaging</a> through training CNN deep learning models. The
						hyperspectral data was captured using a RGB-D and line-scan hyperspectral camera system where
						the ground-truth fat depth data was acquired from CT scans.

						<br><br>

						<u><strong>Results</strong></u> The CNN was compared to a multi-layer perceptron (MLP) and
						linear regression models. The results for R2 and RMSE in Fat Depth are shown for all models in
						the table below. The CNN demonstrated the best fit in fat depth. The maximum fat depth that can
						be accurately estimated by hyperspectral camera was around 15mm.
					<table>
						<thead>
							<tr>
								<th>Model</th>
								<th>R2</th>
								<th>RMSE in Fat Depth (mm)</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Linear Regression</td>
								<td>0.65</td>
								<td>1.78</td>
							</tr>
							<tr>
								<td>MLP</td>
								<td>0.73</td>
								<td>1.57</td>
							</tr>
							<tr>
								<td><strong>CNN</strong></td>
								<td><strong>0.81</strong></td>
								<td><strong>1.17</strong></td>
							</tr>
						</tbody>
					</table>
					</p>
					<!-- <h3><a href="https://github.com/jmehami1/multicamera-calibration-ros"
				target="_blank"><strong>GitHub</strong></a></h3> -->

					<div class="imagerow" id="hyperspectral_deep_learning_fat_depth_top">
						<script>
							displayImagesFromFolderInRow("hyperspectral_deep_learning_fat_depth_top");
						</script>
					</div>
					<div class="imagerow" id="hyperspectral_deep_learning_fat_depth_bottom">
						<script>
							displayImagesFromFolderInRow("hyperspectral_deep_learning_fat_depth_bottom");
						</script>
					</div>
				</div>


				<div class="project">
					<h2>Multi-Camera Extrinsic Calibration in ROS</h2>
					<p>
						<u><strong>Summary</strong></u> I was required to extrinsically calibrate 16 RGB-D cameras with
						partial-overlapping views that were setup in a ROS environment.
						I solved the calibration by creating a double-sided <a
							href="https://docs.opencv.org/4.x/db/da9/tutorial_aruco_board_detection.html"
							target="_blank">ArUco
							board</a> and solved the optimization as a pose graph using <a
							href="https://github.com/RainerKuemmerle/g2o" target="_blank">g2o solver</a>.

						<br><br>

						<u><strong>Results</strong></u> Point cloud data from the cameras was used to create 3D
						reconstructed models. My calibration approach reduced the error in the models by a factor 10
						when compared the previous calibration method. The total calibration time, which includes
						collecting the data and solving the calibration problem, was reduced by over 90% when compared
						to the previous method that calibrated cameras pairwise.
					</p>
					<h3><a href="https://github.com/jmehami1/multicamera-calibration-ros"
							target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="multi_camera_calibration_top">
						<script>
							displayImagesFromFolderInRow("multi_camera_calibration_top");
						</script>
					</div>
					<div class="imagerow" id="multi_camera_calibration_bottom">
						<script>
							displayImagesFromFolderInRow("multi_camera_calibration_bottom");
						</script>
					</div>
				</div>

				<div class="project">
					<h2>Line-scan Frame Camera Calibration</h2>
					<p>
						<u><strong>Summary</strong></u> I was required to calibrate a line-scan hyperspectral camera to
						use for robotic applications. The difficulty with calibrating this camera is the single spatial
						dimension. I successfully implemented the calibration by using an additional 2D color camera
						where the cameras were modelled according to the <a
							href="https://en.wikipedia.org/wiki/Pinhole_camera_model">pinhole
							camera model</a>. This calibration incorporated uncertainty
						estimation due to pixel noise, which was later used to create a novel active calibration
						algorithm (<a href="#pub_observability_line_scan_calibration">see below</a>).
						This work has since been updated to use OpenCV's <a
							href="https://docs.opencv.org/4.x/db/da9/tutorial_aruco_board_detection.html">ArUco
							board</a> for automatic pose estimation of the calibration board.

						<br><br>

						<u><strong>Results</strong></u> The calibration made it possible to reproject line-scan images
						to color images. The active calibration algorithm reduced the error in the calibration
						parameters by 26% while using fewer images when compared to a naive approach that used all
						images.
					</p>
					<h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
							target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="line_scan_frame_camera_calibration_top">
						<script>
							displayImagesFromFolderInRow("line_scan_frame_camera_calibration_top");
						</script>
					</div>
					<div class="imagerow" id="line_scan_frame_camera_calibration_bottom">
						<script>
							displayImagesFromFolderInRow("line_scan_frame_camera_calibration_bottom");
						</script>
					</div>
				</div>


				<!-- <ul class="features">
						<li>
							<span class="icon solid major style1 fa-code"></span>
							<h3>Ipsum consequat</h3>
							<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
								consequat.</p>
							</li>
							<li>
								<span class="icon major style3 fa-copy"></span>
								<h3>Amed sed feugiat</h3>
								<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
									consequat.</p>
								</li>
								<li>
									<span class="icon major style5 fa-gem"></span>
									<h3>Dolor nullam</h3>
									<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
										consequat.</p>
									</li>
								</ul> -->
				<footer class="major">
					<!-- <ul class="actions special">
										<li><a href="generic.html" class="button">Learn More</a></li>
									</ul> -->
				</footer>
			</section>

			<!-- Second Section -->
			<section id="publications" class="main special">
				<header class="major">
					<h2>Publications</h2>

					<script>
						function displayImagesFromFolderInRow(containerId) {
							// This function will load all images that are contained in a local file and add them as image attributes to the publication container.
							var container = document.getElementById(containerId);
							var folderPath = "https://api.github.com/repos/jmehami1/jmehami1.github.io/contents/images/publications/" + container.id;

							function isImageFile(fileName) {
								const imageExtensions = ['jpg', 'jpeg', 'png', 'gif'];
								const fileExtension = fileName.toLowerCase().split('.').pop();

								return imageExtensions.includes(fileExtension);
							}

							(async () => {
								const response = await fetch(folderPath);
								const data = await response.json();
								data.forEach(function (fileElement) {

									var filePath = fileElement.path;
									var fileDownloadUrl = fileElement.download_url;

									if (isImageFile(filePath)) {
										var img = new Image();
										img.src = fileDownloadUrl;
										img.alt = filePath;
										container.appendChild(img);
									}
								});
							})()
						}
					</script>
				</header>
				<!-- <ul class="statistics">
									<li class="style1">
										<span class="icon solid fa-code-branch"></span>
										<strong>5,120</strong> Etiam
									</li>
									<li class="style2">
										<span class="icon fa-folder-open"></span>
										<strong>8,192</strong> Magna
									</li>
									<li class="style3">
										<span class="icon solid fa-signal"></span>
										<strong>2,048</strong> Tempus
									</li>
									<li class="style4">
										<span class="icon solid fa-laptop"></span>
										<strong>4,096</strong> Aliquam
									</li>
									<li class="style5">
										<span class="icon fa-gem"></span>
										<strong>1,024</strong> Nullam
									</li>
								</ul> -->

				<div class="publication">
					<h2><a href="http://hdl.handle.net/10453/164273" target="_blank">Subcutaneous Fat Depth Regression
							Using Hyperspectral and
							Depth Imaging</a></h2>
					<p style="text-align: left;">
						This paper uses a calibrated line-scan hyperspectral and frame camera system with a calibrated
						light source to model the subcutaneous fat depth of lamb cut samples using machine learning. The
						ground-truth fat depth is acquired from ray-casting into CT scans of the lamb cut samples. These
						CT scans are first converted into 3D meshes, which then are aligned to a 3D reconstructed mesh
						from depth images. Finally, the fat depth is acquired through ray-casting hyperspectral pixels.
						Fat depth models are trained using classic and deep learning models, where the deep learning
						models show the best results.
					</p>
					<!-- <h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
											target="_blank"><strong>GitHub</strong></a></h3> -->
					<div class="imagerow" id="subcutaneous_fat_depth_regression">
						<script>
							displayImagesFromFolderInRow("subcutaneous_fat_depth_regression");
						</script>
					</div>
				</div>

				<div class="publication">
					<h2><a href="https://doi.org/10.1109/LRA.2022.3192208" target="_blank">Multi-Modal Non-Isotropic
							Light Source Modelling for Reflectance Estimation in Hyperspectral Imaging</a></h2>
					<p style="text-align: left;">
						This paper improves the estimation of the material property of reflectance for an object of
						interest that is captured using a calibrated line-scan hyperspectral and frame camera system,
						by modeling a light source and incorporating shape information.
						The reflected light from the object of interest is assumed to be described by the dichromatic
						reflectance model. The cameras, light source and objects are all near-field
						where the incident irradiance varies over the object's surface. The light source modeling uses a
						Gaussian Process with a non-zero mean function to capture the spatial irradiance
						of an actual light source. The proposed reflectance estimation involves optimization that uses
						the irradiance estimated from the Gaussian Process model with additional terms that
						involve the surface shape.
					</p>
					<h3><a href="https://github.com/jmehami1/MMHS-RE" target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="multi_modal_non-isotropic_light_source">
						<script>
							displayImagesFromFolderInRow("multi_modal_non-isotropic_light_source");
						</script>
					</div>
					<div class="imagerow" id="multi_modal_non-isotropic_reflectance">
						<script>
							displayImagesFromFolderInRow("multi_modal_non-isotropic_reflectance");
						</script>
					</div>

				</div>

				<div class="publication" id="pub_observability_line_scan_calibration">
					<h2><a href="https://doi.org/10.1109/MFI49285.2020.9235226" target="_blank">Observability driven
							multi-modal line-scan camera calibration</a></h2>
					<p style="text-align: left;">
						This paper improves the calibration of a line-scan camera through a novel active calibration
						algorithm. The line-scan camera is combined with a 2D traditional frame camera (color or RGB
						camera). The active calibration algorithm filters through the calibration dataset and only uses
						images that improve parameter estimation through calculation of the observability.
					</p>
					<h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
							target="_blank"><strong>GitHub</strong></a></h3>
					<div class="imagerow" id="observability_line_scan_calibration">
						<script>
							displayImagesFromFolderInRow("observability_line_scan_calibration");
						</script>
					</div>
				</div>

				<footer class="major">
					<ul class="actions special">
						<li><a href="https://scholar.google.com/citations?user=j3bTQ84AAAAJ&hl=en&oi=ao" class="button"
								target="_blank">More Details</a></li>
					</ul>
				</footer>
			</section>

			<!-- Get Started -->
			<section id="education" class="main special">
				<header class="major">
					<h2>Education</h2>
				</header>

				<div class="education">
					<img src="images/uts_logo.png" />
					<h3><strong>PhD in Robotics</strong></h3>

					<h3 class="university">University of Technology Sydney </h3>
					<h3 class="university">Sydney, Australia</h3>

					<h3 class="year">January 2019 to July 2023</h3>
					<p><strong>Topic:</strong> Subsurface Material Property Estimation using Hyperspectral Imaging</p>
				</div>


				<div class="education">

					<img src="images/uoa_logo.png" />
					<h3><strong>Bachelor of Engineering (Honors) specializing in Mechatronics</strong></h3>

					<h3 class="university">The University of Auckland</h3>
					<h3 class="university">Auckland, New Zealand</h3>

					<h3 class="year">January 2014 to July 2018</h3>
					<p>Graduated with first class honors</p>

					<!-- <footer class="major">
															<ul class="actions special">
																<li><a href="generic.html" class="button primary">Get Started</a></li>
																<li><a href="generic.html" class="button">Learn More</a></li>
															</ul>
														</footer> -->
			</section>

		</div>

		<!-- Footer -->
		<footer id="footer">
			<!-- <section>
				<h2>Aliquam sed mauris</h2>
														<p>Sed lorem ipsum dolor sit amet et nullam consequat feugiat consequat magna adipiscing tempus etiam
															dolore veroeros. eget dapibus mauris. Cras aliquet, nisl ut viverra sollicitudin, ligula erat
															egestas velit, vitae tincidunt odio.</p>
															<ul class="actions">
																<li><a href="generic.html" class="button">Learn More</a></li>
															</ul>
			</section> -->
			<h2>Jesse Mehami</h2>
			<h2><strong>AKA</strong> Jasprabhjit Mehami</h2>

			<dl class="alt">
				<dt>Location</dt>
				<dd>Sydney, Australia</dd>
				<dt>Email</dt>
				<dd><a href="mailto:jmehami@outlook.com">jmehami@outlook.com</a></dd>
			</dl>


			<ul class="icons">
				<li>
					<a href="https://www.linkedin.com/in/jessemehami" class="icon brands fa-linkedin alt"
						title="LinkedIn">
					</a>
				</li>
				<li>
					<a href="https://github.com/jmehami1" class="icon brands fa-github alt" title="GitHub">
					</a>
				</li>
				<li>
					<a href="https://scholar.google.com/citations?user=j3bTQ84AAAAJ&hl=en&oi=ao" class="icon fa fa-graduation-cap alt" title="Google Scholar">
					</a>
				</li>
			</ul>

			<p class="copyright">&copy; Design: <a href="https://html5up.net">HTML5 UP</a>. Updated July 2024.</p>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>